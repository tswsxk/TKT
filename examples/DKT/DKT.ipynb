{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Deep Knowledge Tracing\n",
    "\n",
    "This notebook will show you how to train and use the DKT.\n",
    "First, we will show how to get the data (here we use a0910 as the dataset).\n",
    "Then we will show how to train a DKT and perform the parameters persistence.\n",
    "At last, we will show how to load the parameters from the file and evaluate on the test dataset.\n",
    "\n",
    "The script version could be found in [DKT.py](DKT.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation\n",
    "\n",
    "Before we process the data, we need to first acquire the dataset which is shown in [prepare_dataset.ipynb](prepare_dataset.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading data from ../../data/a0910c/train.json: 3966it [00:00, 16765.33it/s]\n",
      "batchify: 100%|██████████| 130/130 [00:00<00:00, 1277.91it/s]\n",
      "reading data from ../../data/a0910c/valid.json: 472it [00:00, 39438.06it/s]\n",
      "e:\\program\\eduktm\\EduKTM\\utils\\torch\\extlib\\sampler.py:327: UserWarning: Some buckets are empty and will be removed. Unused bucket keys=[55, 58, 59, 61, 65, 69, 74, 76, 77, 79, 80, 88, 90, 94, 95, 96, 99]\n",
      "  warnings.warn('Some buckets are empty and will be removed. Unused bucket keys=%s' %\n",
      "batchify: 100%|██████████| 84/84 [00:00<00:00, 5615.22it/s]\n",
      "reading data from ../../data/a0910c/test.json: 1088it [00:00, 54547.66it/s]\n",
      "e:\\program\\eduktm\\EduKTM\\utils\\torch\\extlib\\sampler.py:327: UserWarning: Some buckets are empty and will be removed. Unused bucket keys=[73, 88]\n",
      "  warnings.warn('Some buckets are empty and will be removed. Unused bucket keys=%s' %\n",
      "batchify: 100%|██████████| 101/101 [00:00<00:00, 3492.23it/s]\n"
     ]
    }
   ],
   "source": [
    "from TKT.DKT import etl\n",
    "batch_size = 64\n",
    "train = etl(\"../../data/a0910c/train.json\", batch_size=batch_size)\n",
    "valid = etl(\"../../data/a0910c/valid.json\", batch_size=batch_size)\n",
    "test = etl(\"../../data/a0910c/test.json\", batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training and Persistence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x2cf99356df0>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger: <Logger model (INFO)>\n",
      "model_name: model\n",
      "model_dir: model\n",
      "begin_epoch: 0\n",
      "end_epoch: 2\n",
      "batch_size: 32\n",
      "save_epoch: 1\n",
      "optimizer: Adam\n",
      "optimizer_params: {'lr': 0.001, 'weight_decay': 0.0001}\n",
      "lr_params: {}\n",
      "train_select: None\n",
      "save_select: None\n",
      "ctx: cpu\n",
      "train_ctx: None\n",
      "eval_ctx: None\n",
      "toolbox_params: {}\n",
      "hyper_params: {'ku_num': 146, 'hidden_num': 100}\n",
      "init_params: {}\n",
      "loss_params: {}\n",
      "caption: \n",
      "validation_result_file: model\\result.json\n",
      "cfg_path: model\\configuration.json\n",
      "Epoch| Total-E          Batch     Total-B       Loss-SequenceLogisticMaskLoss             Progress           \n",
      "    0|       1            130         130                            0.337137     [00:03<00:00, 33.09it/s]   \n",
      "Epoch [0]\tLoss - SequenceLogisticMaskLoss: 0.337137\n",
      "           precision    recall        f1  support\n",
      "0           0.528108  0.251642  0.340863     7765\n",
      "1           0.707490  0.889501  0.788123    15801\n",
      "macro_avg   0.617799  0.570571  0.564493    23566\n",
      "accuracy: 0.679326\tmacro_auc: 0.627901\tmacro_aupoc: 0.751432\n",
      "Epoch| Total-E          Batch     Total-B       Loss-SequenceLogisticMaskLoss             Progress           \n",
      "    1|       1            130         130                            0.151321     [00:03<00:00, 32.56it/s]   \n",
      "Epoch [1]\tLoss - SequenceLogisticMaskLoss: 0.151321\n",
      "           precision    recall        f1  support\n",
      "0           0.523115  0.429878  0.471936     7765\n",
      "1           0.742392  0.807417  0.773540    15801\n",
      "macro_avg   0.632754  0.618647  0.622738    23566\n",
      "accuracy: 0.683018\tmacro_auc: 0.672586\tmacro_aupoc: 0.779806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 84/84 [00:00<00:00, 227.63it/s]\n",
      "evaluating: 100%|██████████| 84/84 [00:00<00:00, 235.00it/s]\n",
      "model, INFO writing configuration parameters to E:\\Program\\TKT\\examples\\DKT\\dkt\\configuration.json\n"
     ]
    },
    {
     "data": {
      "text/plain": "'dkt'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from TKT import DKT\n",
    "model = DKT(hyper_params=dict(ku_num=146, hidden_num=100))\n",
    "model.train(train, valid, end_epoch=2)\n",
    "model.save(\"dkt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading and Testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "evaluating: 100%|██████████| 101/101 [00:00<00:00, 158.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall        f1  support\n",
      "0           0.544407  0.461209  0.499366    17517\n",
      "1           0.735044  0.794773  0.763742    32944\n",
      "macro_avg   0.639725  0.627991  0.631554    50461\n",
      "accuracy: 0.678980\tmacro_auc: 0.680546\tmacro_aupoc: 0.771561\n"
     ]
    }
   ],
   "source": [
    "model = DKT.from_pretrained(\"dkt\")\n",
    "print(model.eval(test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}